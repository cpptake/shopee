{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 参照\n\nhttps://www.kaggle.com/tanulsingh077/pytorch-metric-learning-pipeline-only-images\n\nhttps://www.kaggle.com/zzy990106/b0-bert-cv0-9","metadata":{}},{"cell_type":"markdown","source":"# ver11\n\nText　を　数字　⇒　英語に変換\n\nCV:0.8407\n\n# 12\n\nText　を　数字　⇒　英語の文章に変換\nCV:0.843///\n\nCV:0.8410\n","metadata":{}},{"cell_type":"markdown","source":"# BM\n\nbase_lr = 5e-4  CV:0.8436\n\nbert_lr = 3e-5  CV:0.8320\n\nbert_lr = 5e-6 CV:0.8436\n\nbert_lr = 5e-5 CV: 0.8297\n\n\n## AddMarginProduct\ns=30.0, m=0.40\nbert_lr=5e-6,base_lr=5e-4,dropout = 0.5\n\nCV:0.8399\n\nm = 30\n\nCV:0.8356\n\nm=70\n\nCV:0.8390\n\n\n## Adacos\nm = 0.5\nbert_lr=5e-6,base_lr=5e-4,dropout = 0.5\n\nCV:0.8325\n\nm＝0.3\n\nCV:0.8363","metadata":{}},{"cell_type":"markdown","source":"## 追伸\n元のモデルだとCUDA OOMで走らなかったため\n\nbatchsize 16 ⇒ 8に変更\n\n計算遅すぎ問題\n\n(CVは１Fold目のみ）\n* dim 512 batch 8　⇒　2s/ite で　CV 0.81~~　くらい（3426）\n* dim 256 batch 8　⇒　3.3s/ite で　CV 0.8025（3426）\n* dim 256 batch 16　⇒　2.3/ite で　CV 0.8059（1713）\n","metadata":{}},{"cell_type":"code","source":"!pip install timm","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:40:29.201004Z","iopub.execute_input":"2021-05-26T13:40:29.201386Z","iopub.status.idle":"2021-05-26T13:40:37.759028Z","shell.execute_reply.started":"2021-05-26T13:40:29.201304Z","shell.execute_reply":"2021-05-26T13:40:37.758064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install mlflow","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:40:37.76166Z","iopub.execute_input":"2021-05-26T13:40:37.762276Z","iopub.status.idle":"2021-05-26T13:40:52.879642Z","shell.execute_reply.started":"2021-05-26T13:40:37.762239Z","shell.execute_reply":"2021-05-26T13:40:52.878579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer, AutoModel\nfrom torch.utils.data import Dataset, DataLoader\nfrom timm import create_model\nimport math\nimport cv2\nimport random\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.neighbors import NearestNeighbors\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, StepLR\nfrom torch.optim import Adam, Optimizer, SGD\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport dataclasses\nimport tqdm\nfrom datetime import datetime as dt\nimport time\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T13:40:52.880987Z","iopub.execute_input":"2021-05-26T13:40:52.881256Z","iopub.status.idle":"2021-05-26T13:40:57.976524Z","shell.execute_reply.started":"2021-05-26T13:40:52.881229Z","shell.execute_reply":"2021-05-26T13:40:57.975704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\ntimm.list_models(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:40:57.97757Z","iopub.execute_input":"2021-05-26T13:40:57.977987Z","iopub.status.idle":"2021-05-26T13:40:57.994447Z","shell.execute_reply.started":"2021-05-26T13:40:57.977943Z","shell.execute_reply":"2021-05-26T13:40:57.993661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n / (len(row.target)+len(row[col]))\n    return f1score\n\n\n@dataclasses.dataclass\nclass Config:\n    # model\n    linear_out = 512\n    dropout = 0.5\n    model_name = \"efficientnet_b2\"#efficientnet_b3\n#     nlp_model_name = \"bert-base-multilingual-uncased\"\n    nlp_model_name = \"bert-base-uncased\"\n    bert_agg = \"mean\"\n\n    # arcmargin\n    m = 0.5\n    s = 32\n\n    # dim\n#     dim = (512, 512)\n    dim = (256, 256)\n\n    # optim\n    optimizer: Optimizer = Adam\n    optimizer_params = {}\n    base_lr = 5e-4#original 1e-4\n    bert_lr = 5e-6#original 1e-5\n\n    scheduler = ReduceLROnPlateau\n    scheduler_params = {\"patience\": 1, \"factor\": 0.1, \"mode\": \"max\"}\n\n    loss = nn.CrossEntropyLoss\n    loss_params = {}\n\n    # training\n    batch_size = 16#original …　16\n    num_workers = 1\n\n    epochs = 10#30\n    early_stop_round = 3\n\n    # debug mode\n    debug = False\n\n    # transforms\n    train_transforms = albumentations.Compose([\n            albumentations.Resize(int(dim[0] * 1.1),\n                                  int(dim[1] * 1.1), always_apply=True),\n            albumentations.CenterCrop(dim[0], dim[1], p=0.5),\n            albumentations.Resize(dim[0], dim[1], always_apply=True),\n            albumentations.Normalize(),\n            ToTensorV2(p=1.0),\n    ])\n    val_transforms = albumentations.Compose([\n            albumentations.Resize(dim[0], dim[1], always_apply=True),\n            albumentations.Normalize(),\n            ToTensorV2(p=1.0),\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:10:20.144752Z","iopub.execute_input":"2021-05-24T13:10:20.145334Z","iopub.status.idle":"2021-05-24T13:10:20.158529Z","shell.execute_reply.started":"2021-05-24T13:10:20.145296Z","shell.execute_reply":"2021-05-24T13:10:20.157627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class NN(nn.Module):\n#     def __init__(self,pretrained: bool = True,num_classes=11014):\n#         self.cnn = create_model(config.model_name,\n#                                 pretrained=pretrained,\n#                                 num_classes=0)\n        \n# modelname2 = 'resnest50d'\n        \n# nn = create_model(modelname2,\n#                 pretrained=True,\n#                 num_classes=0)\n\n\n# # nn.eval()\n# matrix = torch.rand(2, 3,224,224)\n\n# nn(matrix).size() # (2, 1000)\n\n# ans  = nn.forward_features(matrix)\n# ans.size() # (2, 1536, 7, 7)\n\nclass ShopeeNet_test(nn.Module):\n    def __init__(self,\n                 config: Config,\n                 bert=None,\n                 pretrained: bool = True,\n                 num_classes=11014):\n        super().__init__()\n        self.config = config\n        if bert is None:\n            self.bert = AutoModel.from_pretrained(config.nlp_model_name)\n        else:\n            self.bert = bert\n#         self.bert_bn = nn.BatchNorm1d(self.bert.config.hidden_size)\n        self.cnn = create_model(config.model_name,\n                                pretrained=pretrained,\n                                num_classes=0)\n        self.cnn_bn = nn.BatchNorm1d(self.cnn.num_features)\n\n#         n_feat_concat = self.cnn.num_features + self.bert.config.hidden_size\n        self.fc = nn.Sequential(\n            nn.Linear(self.cnn.num_features, config.linear_out),\n            nn.BatchNorm1d(config.linear_out)\n        )\n        self.dropout = nn.Dropout(config.dropout)\n        self.final = ArcMarginProduct(s=config.s,\n                                      m=config.m,\n                                      in_features=config.linear_out,\n                                      out_features=num_classes)\n#         self.final = AdaCos(m=config.m,\n#                             in_features=config.linear_out,\n#                             out_features=num_classes)\n    \n    def forward(self, X_image, input_ids, attention_mask, label=None):\n        x = self.cnn(X_image)\n        x = self.cnn_bn(x)\n        x = self.dropout(x)\n\n#         text = self.bert(input_ids=input_ids, attention_mask=attention_mask)[0].mean(axis=1)\n#         text = self.bert_bn(text)\n#         text = self.dropout(text)\n\n#         x = torch.cat([x, text], dim=1)\n        ret = self.fc(x)\n\n        if label is not None:\n            x = self.final(ret, label)\n            return x, ret\n        else:\n            return ret","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:11:51.133276Z","iopub.execute_input":"2021-05-24T13:11:51.133626Z","iopub.status.idle":"2021-05-24T13:11:51.143807Z","shell.execute_reply.started":"2021-05-24T13:11:51.133597Z","shell.execute_reply":"2021-05-24T13:11:51.142957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShopeeNet(nn.Module):\n    def __init__(self,\n                 config: Config,\n                 bert=None,\n                 pretrained: bool = True,\n                 num_classes=11014):\n        super().__init__()\n        self.config = config\n        if bert is None:\n            self.bert = AutoModel.from_pretrained(config.nlp_model_name)\n        else:\n            self.bert = bert\n        self.bert_bn = nn.BatchNorm1d(self.bert.config.hidden_size)\n        self.cnn = create_model(config.model_name,\n                                pretrained=pretrained,\n                                num_classes=0)\n        self.cnn_bn = nn.BatchNorm1d(self.cnn.num_features)\n\n        n_feat_concat = self.cnn.num_features + self.bert.config.hidden_size\n        self.fc = nn.Sequential(\n            nn.Linear(n_feat_concat, config.linear_out),\n            nn.BatchNorm1d(config.linear_out)\n        )\n        self.dropout = nn.Dropout(config.dropout)\n        self.final = ArcMarginProduct(s=config.s,\n                                      m=config.m,\n                                      in_features=config.linear_out,\n                                      out_features=num_classes)\n#         self.final = AdaCos(m=config.m,\n#                             in_features=config.linear_out,\n#                             out_features=num_classes)\n    \n    def forward(self, X_image, input_ids, attention_mask, label=None):\n        x = self.cnn(X_image)\n        x = self.cnn_bn(x)\n        x = self.dropout(x)\n\n        text = self.bert(input_ids=input_ids, attention_mask=attention_mask)[0].mean(axis=1)\n        text = self.bert_bn(text)\n        text = self.dropout(text)\n\n        x = torch.cat([x, text], dim=1)\n        ret = self.fc(x)\n\n        if label is not None:\n            x = self.final(ret, label)\n            return x, ret\n        else:\n            return ret\n        \n        \nclass ArcMarginProduct(nn.Module):\n    r\"\"\"Implement of large margin arc distance: :\n        Args:\n            in_features: size of each input sample\n            out_features: size of each output sample\n            s: norm of input feature\n            m: margin\n            cos(theta + m)\n        \"\"\"\n    def __init__(self, in_features, out_features, s, m, easy_margin=False):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, input, label):\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------------\n        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n        one_hot = torch.zeros(cosine.size(), device='cuda')\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n        output *= self.s\n        # print(output)\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:11:55.717238Z","iopub.execute_input":"2021-05-24T13:11:55.717567Z","iopub.status.idle":"2021-05-24T13:11:55.737083Z","shell.execute_reply.started":"2021-05-24T13:11:55.717539Z","shell.execute_reply":"2021-05-24T13:11:55.736331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AdaCos(nn.Module):\n    def __init__(self, in_features, out_features, m=0.50, ls_eps=0, theta_zero=math.pi/4):\n        super(AdaCos, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.theta_zero = theta_zero\n        self.s = math.log(out_features - 1) / math.cos(theta_zero)\n        self.m = m\n        self.ls_eps = ls_eps  # label smoothing\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n    def forward(self, input, label):\n        # normalize features\n        x = F.normalize(input)\n        # normalize weights\n        W = F.normalize(self.weight)\n        # dot product\n        logits = F.linear(x, W)\n        # add margin\n        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n        target_logits = torch.cos(theta + self.m)\n        one_hot = torch.zeros_like(logits)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n        output = logits * (1 - one_hot) + target_logits * one_hot\n        # feature re-scale\n        with torch.no_grad():\n            B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n            B_avg = torch.sum(B_avg) / input.size(0)\n            theta_med = torch.median(theta)\n            self.s = torch.log(B_avg) / torch.cos(torch.min(self.theta_zero * torch.ones_like(theta_med), theta_med))\n        output *= self.s\n\n        return output\n    \nclass AddMarginProduct(nn.Module):\n    r\"\"\"Implement of large margin cosine distance: :\n    Args:\n        in_features: size of each input sample\n        out_features: size of each output sample\n        s: norm of input feature\n        m: margin\n        cos(theta) - m\n    \"\"\"\n\n    def __init__(self, in_features, out_features, s=30.0, m=0.40):\n        super(AddMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n    def forward(self, input, label):\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        phi = cosine - self.m\n        # --------------------------- convert label to one-hot ---------------------------\n        one_hot = torch.zeros(cosine.size(), device='cuda')\n        # one_hot = one_hot.cuda() if cosine.is_cuda else one_hot\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n        output *= self.s\n        # print(output)\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:11:56.16289Z","iopub.execute_input":"2021-05-24T13:11:56.163232Z","iopub.status.idle":"2021-05-24T13:11:56.177848Z","shell.execute_reply.started":"2021-05-24T13:11:56.163195Z","shell.execute_reply":"2021-05-24T13:11:56.176751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ShopeeDataset(Dataset):\n    def __init__(self, df, tokenizer, transforms=None):\n        self.df = df.reset_index()\n        self.augmentations = transforms\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n\n        text = row.title\n\n        image = cv2.imread(row.filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        text = self.tokenizer(text, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n        input_ids = text[\"input_ids\"][0]\n        attention_mask = text[\"attention_mask\"][0]\n        if self.augmentations:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']\n\n        return image, input_ids, attention_mask, torch.tensor(row.label_group)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:11:56.576983Z","iopub.execute_input":"2021-05-24T13:11:56.577317Z","iopub.status.idle":"2021-05-24T13:11:56.584806Z","shell.execute_reply.started":"2021-05-24T13:11:56.577285Z","shell.execute_reply":"2021-05-24T13:11:56.583692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:11:57.034195Z","iopub.execute_input":"2021-05-24T13:11:57.034541Z","iopub.status.idle":"2021-05-24T13:11:57.042208Z","shell.execute_reply.started":"2021-05-24T13:11:57.034503Z","shell.execute_reply":"2021-05-24T13:11:57.039109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(dataloader, model, criterion, optimizer, device, scheduler, epoch):\n    import mlflow\n\n    model.train()\n    loss_score = AverageMeter()\n\n    tk0 = tqdm.tqdm(enumerate(dataloader), total=len(dataloader))\n    for bi, d in tk0:\n        batch_size = d[0].shape[0]\n\n        images = d[0].to(device)\n        input_ids = d[1].to(device)\n        attention_mask = d[2].to(device)\n        targets = d[3].to(device)\n\n        optimizer.zero_grad()\n\n        output, _ = model(images, input_ids, attention_mask, targets)\n\n        loss = criterion(output, targets)\n\n        loss.backward()\n        optimizer.step()\n\n        loss_score.update(loss.detach().item(), batch_size)\n        tk0.set_postfix(Train_Loss=loss_score.avg, Epoch=epoch, LR=optimizer.param_groups[0]['lr'])\n\n        if scheduler.__class__ != ReduceLROnPlateau:\n            scheduler.step()\n        mlflow.log_metric(\"train_loss\", loss.detach().item())\n\n    return loss_score\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:11:58.965067Z","iopub.execute_input":"2021-05-24T13:11:58.965411Z","iopub.status.idle":"2021-05-24T13:11:58.976046Z","shell.execute_reply.started":"2021-05-24T13:11:58.965378Z","shell.execute_reply":"2021-05-24T13:11:58.975334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef eval_fn(data_loader, model, criterion, device, df_val):\n    loss_score = AverageMeter()\n\n    model.eval()\n    tk0 = tqdm.tqdm(enumerate(data_loader), total=len(data_loader))\n\n    all_features = []\n    all_targets = []\n    with torch.no_grad():\n        for bi, d in tk0:\n            batch_size = d[0].size()[0]\n\n            images = d[0].to(device)\n            input_ids = d[1].to(device)\n            attention_mask = d[2].to(device)\n            targets = d[3].to(device)\n\n            output, feature = model(images, input_ids, attention_mask, targets)\n\n            loss = criterion(output, targets)\n\n            loss_score.update(loss.detach().item(), batch_size)\n            tk0.set_postfix(Eval_Loss=loss_score.avg)\n\n            all_features.extend(feature.detach().cpu().numpy())\n            all_targets.extend(targets.detach().cpu().numpy())\n\n    all_features = np.array(all_features, dtype=np.float32)\n\n    best_score, best_th, df_best = get_best_neighbors(df=df_val, embeddings=all_features)\n\n    return loss_score, best_score, best_th, df_best\n\n\ndef get_cv(df):\n    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n    df['target'] = df.label_group.map(tmp)\n    df['f1'] = df.apply(getMetric('pred'),axis=1)\n    return df.f1.mean()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:11:59.534045Z","iopub.execute_input":"2021-05-24T13:11:59.534395Z","iopub.status.idle":"2021-05-24T13:11:59.544648Z","shell.execute_reply.started":"2021-05-24T13:11:59.534366Z","shell.execute_reply":"2021-05-24T13:11:59.543519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_best_neighbors(embeddings, df):\n\n    if len(df) > 50:\n        model = NearestNeighbors(n_neighbors=50, )\n    else:\n        model = NearestNeighbors(n_neighbors=len(df) - 1)\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n\n    print(\"threshold search\")\n\n    best_th = 0\n    best_score = 0\n\n    posting_ids = df[\"posting_id\"].values\n    print(f\"distances shape: {distances.shape} mean: {distances.mean()}, std: {distances.std()}\")\n    for th in np.arange(0, 5, 0.1).tolist() + np.arange(5, 10, 0.2).tolist() + np.arange(10, 20, 0.5).tolist() + np.arange(20, 50, 3).tolist():\n        preds = []\n        for i in range(len(distances)):\n            IDX = np.where(distances[i,] < th)[0]\n            ids = indices[i, IDX]\n            o = posting_ids[ids]\n            preds.append(o)\n        df[\"pred\"] = preds\n        score = get_cv(df)\n\n        if best_score < score:\n            best_th = th\n            best_score = score\n            df_best = df.copy()\n        print(\"th={:.4f} , score={:.4f}\".format(th, score))\n\n    return best_score, best_th, df_best","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:12:00.571517Z","iopub.execute_input":"2021-05-24T13:12:00.571833Z","iopub.status.idle":"2021-05-24T13:12:00.580114Z","shell.execute_reply.started":"2021-05-24T13:12:00.571803Z","shell.execute_reply":"2021-05-24T13:12:00.579305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def title_number_to_str(df):\n#     num_list = ['0','1','2','3','4','5','6','7','8','9']\n#     str_list = ['zero','one','two','three','four','five','six','seven','eight','nine']\n    \n#     for i,j in zip(num_list,str_list):\n#         df['title'] = df['title'].str.replace(i, j)\n        \n#     return df\n\ndef title_number_to_str(df):\n    regex = re.compile('\\d+')\n    title = df['title']\n    \n    for row in range(len(title)):\n        text = title[row]\n        odds = []\n        \n        for line in text.splitlines():\n            match = regex.findall(line)\n            \n            for i in match:\n                num_str = num_to_str(int(i))\n                odds.append(num_str)\n            \n            for j,k in zip(match,odds):\n                title[row] = df['title'][row].replace(j, k)\n    \n    df['title'] = title\n    \n    return df\n\ndef num_to_str(n):\n    a = [\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\"]\n    b = [\"ten\",\"twenty\",\"thirty\",\"forty\",\"fifty\",\"sixty\",\"seventy\",\"eighty\",\"ninety\"]\n    c = [\"eleven\",\"twelve\",\"thirteen\",\"fourteen\",\"fifteen\",\"sixteen\",\"seventeen\",\"eighteen\",\"nineteen\"]\n    \n    #1000の位の計算\n    dd = n//1000\n    \n    #100の位の計算(nを100で割った整数を求める)\n    d = n // 100\n    #10の位の計算(nからd * 100の値を引いた数を10で割った整数を求める)\n    e = (n - d * 100) // 10\n    #1の位の計算(nからd * 100の値を引いた数を10で割った余りを求める)\n    f = (n - d * 100) % 10\n    \n    if dd >= 1:\n        return str(n)\n\n    if n >= 11 and n <= 19:  #nが11~19の数かを調べる\n        return c[n-11]\n    elif d  == 0:#100の位があるか調べる\n        if  e == 0:#10の位があるか調べる\n            return a[f-1]\n        elif f == 0:#1の位があるか調べる\n            return b[e-1]\n        else:\n            return b[e-1] + \"-\" + a[f-1]\n    elif e == 0:\n        if f == 0:\n            return a[d-1] + \" hundred\"\n        else:\n            return a[d-1] + \" hundred and \" + a[f-1]\n    else:\n        if f == 0:\n            return a[d-1] + \" hundred and \" + b[e-1]\n        else:\n            return a[d-1] + \" hundred and \" + b[e-1] + \"-\" + a[f-1]","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:12:03.760006Z","iopub.execute_input":"2021-05-24T13:12:03.760348Z","iopub.status.idle":"2021-05-24T13:12:03.774129Z","shell.execute_reply.started":"2021-05-24T13:12:03.760318Z","shell.execute_reply":"2021-05-24T13:12:03.77309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_torch(19900222)\noutput_dir = \"./\"\n\n#     df = pd.read_csv(\"../input/train-fold/train_fold.csv\")\ndf = pd.read_csv(\"../input/train-fold-translate/train_fold_translate.csv\")\ndf[\"filepath\"] = df['image'].apply(lambda x: os.path.join('../input/shopee-product-matching/', 'train_images', x))\nlabel_encoder = LabelEncoder()\ndf[\"label_group\"] = label_encoder.fit_transform(df[\"label_group\"].values)\n\nif Config.debug:\n    df = df.iloc[:100]\n\ntokenizer = AutoTokenizer.from_pretrained(Config.nlp_model_name)\n\nif Config.debug:\n    df = df.iloc[:100]","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:12:04.815708Z","iopub.execute_input":"2021-05-24T13:12:04.816021Z","iopub.status.idle":"2021-05-24T13:12:09.682657Z","shell.execute_reply.started":"2021-05-24T13:12:04.815985Z","shell.execute_reply":"2021-05-24T13:12:09.681732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import mlflow\n\nfor fold in [0]:\n#         mlflow.start_run(experiment_id=0,\n#                          run_name=os.path.basename(__file__))\n\n    df_train = df[df[\"fold\"] != 0]\n    df_val = df[df[\"fold\"] == 0]\n\n#         df_train = df[df[\"fold\"] != fold]\n#         df_val = df[df[\"fold\"] == fold]\n    # df_train = df[df[\"label_group\"] % 5 != 0]\n    # df_val = df[df[\"label_gConfig % 5 == 0]\n\n    \n    train_dataset = ShopeeDataset(df=df_train,\n                                  transforms=Config.train_transforms,\n                                  tokenizer=tokenizer)\n    val_dataset = ShopeeDataset(df=df_val,\n                                transforms=Config.val_transforms,\n                                tokenizer=tokenizer)\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=Config.batch_size,\n        shuffle=True,\n        pin_memory=True,\n        drop_last=True,\n        num_workers=Config.num_workers\n    )\n\n    val_loader = torch.utils.data.DataLoader(\n        val_dataset,\n        batch_size=Config.batch_size,\n        num_workers=Config.num_workers,\n        shuffle=False,\n        pin_memory=True,\n        drop_last=False,\n    )\n\n    device = torch.device(\"cuda\")\n\n    model = ShopeeNet_test(config=Config)\n    model.to(\"cuda\")\n    optimizer = Config.optimizer(params=[\n#                                             {\"params\": model.bert.parameters(), \"lr\": Config.bert_lr},\n#                                          {\"params\": model.bert_bn.parameters(), \"lr\": Config.bert_lr},\n                                         {\"params\": model.cnn.parameters(), \"lr\": Config.base_lr},\n                                         {\"params\": model.cnn_bn.parameters(), \"lr\": Config.base_lr},\n                                         {\"params\": model.fc.parameters(), \"lr\": Config.base_lr},\n                                         {\"params\": model.final.parameters(), \"lr\": Config.base_lr}])\n    scheduler = Config.scheduler(optimizer, **Config.scheduler_params)\n    criterion = Config.loss(**Config.loss_params)\n\n    best_score = 0\n    not_improved_epochs = 0\n\n    print(\"model set done\")\n    for epoch in range(Config.epochs):\n        train_loss = train_fn(train_loader, model, criterion, optimizer, device, scheduler=scheduler, epoch=epoch)\n        valid_loss, score, best_threshold, df_best = eval_fn(val_loader, model, criterion, device, df_val)\n#             valid_loss = eval_fn(val_loader, model, criterion, device, df_val)\n        scheduler.step(score)\n\n        print(f\"CV: {score}\")\n        if score > best_score:\n            print('best model found for epoch {}, {:.4f} -> {:.4f}'.format(epoch, best_score, score))\n            best_score = score\n            torch.save(model.state_dict(), f'{output_dir}/best_fold{fold}.pth')\n            not_improved_epochs = 0\n#             mlflow.log_metric(\"val_best_cv_score\", score)\n            df_best.to_csv(f\"{output_dir}/df_val_fold{fold}.csv\", index=False)\n            \n        else:\n            not_improved_epochs += 1\n            print('{:.4f} is not improved from {:.4f} epoch {} / {}'.format(score, best_score, not_improved_epochs, Config.early_stop_round))\n            if not_improved_epochs >= Config.early_stop_round:\n                print(\"finish training.\")\n                break\n#         mlflow.log_param(\"fold\", fold)\n#         mlflow.log_metric(\"val_loss\", valid_loss.avg)\n#         mlflow.log_metric(\"val_cv_score\", score)\n#         mlflow.log_metric(\"val_best_threshold\", best_threshold)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:14:04.938349Z","iopub.execute_input":"2021-05-24T13:14:04.938679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef main(config):\n    import mlflow\n    seed_torch(19900222)\n    output_dir = \"./\"\n\n#     df = pd.read_csv(\"../input/train-fold/train_fold.csv\")\n    df = pd.read_csv(\"../input/train-fold-translate/train_fold_translate.csv\")\n    df[\"filepath\"] = df['image'].apply(lambda x: os.path.join('../input/shopee-product-matching/', 'train_images', x))\n    label_encoder = LabelEncoder()\n    df[\"label_group\"] = label_encoder.fit_transform(df[\"label_group\"].values)\n    \n    # 数字を英語に変換する処理\n#     df = title_number_to_str(df)\n    \n    \n    if config.debug:\n        df = df.iloc[:100]\n\n    tokenizer = AutoTokenizer.from_pretrained(config.nlp_model_name)\n\n    if config.debug:\n        df = df.iloc[:100]\n    for fold in [0]:\n#         mlflow.start_run(experiment_id=0,\n#                          run_name=os.path.basename(__file__))\n\n        df_train = df[df[\"fold\"] != 0]\n        df_val = df[df[\"fold\"] == 0]\n\n#         df_train = df[df[\"fold\"] != fold]\n#         df_val = df[df[\"fold\"] == fold]\n        # df_train = df[df[\"label_group\"] % 5 != 0]\n        # df_val = df[df[\"label_group\"] % 5 == 0]\n\n        train_dataset = ShopeeDataset(df=df_train,\n                                      transforms=config.train_transforms,\n                                      tokenizer=tokenizer)\n        val_dataset = ShopeeDataset(df=df_val,\n                                    transforms=config.val_transforms,\n                                    tokenizer=tokenizer)\n\n        train_loader = torch.utils.data.DataLoader(\n            train_dataset,\n            batch_size=config.batch_size,\n            shuffle=True,\n            pin_memory=True,\n            drop_last=True,\n            num_workers=config.num_workers\n        )\n\n        val_loader = torch.utils.data.DataLoader(\n            val_dataset,\n            batch_size=config.batch_size,\n            num_workers=config.num_workers,\n            shuffle=False,\n            pin_memory=True,\n            drop_last=False,\n        )\n\n        device = torch.device(\"cuda\")\n\n        model = ShopeeNet(config=config)\n        model.to(\"cuda\")\n        optimizer = config.optimizer(params=[{\"params\": model.bert.parameters(), \"lr\": config.bert_lr},\n                                             {\"params\": model.bert_bn.parameters(), \"lr\": config.bert_lr},\n                                             {\"params\": model.cnn.parameters(), \"lr\": config.base_lr},\n                                             {\"params\": model.cnn_bn.parameters(), \"lr\": config.base_lr},\n                                             {\"params\": model.fc.parameters(), \"lr\": config.base_lr},\n                                             {\"params\": model.final.parameters(), \"lr\": config.base_lr}])\n        scheduler = config.scheduler(optimizer, **config.scheduler_params)\n        criterion = config.loss(**config.loss_params)\n\n        best_score = 0\n        not_improved_epochs = 0\n        \n        print(\"model set done\")\n        for epoch in range(config.epochs):\n            train_loss = train_fn(train_loader, model, criterion, optimizer, device, scheduler=scheduler, epoch=epoch)\n            valid_loss, score, best_threshold, df_best = eval_fn(val_loader, model, criterion, device, df_val)\n#             valid_loss = eval_fn(val_loader, model, criterion, device, df_val)\n            scheduler.step(score)\n\n            print(f\"CV: {score}\")\n            if score > best_score:\n                print('best model found for epoch {}, {:.4f} -> {:.4f}'.format(epoch, best_score, score))\n                best_score = score\n                torch.save(model.state_dict(), f'{output_dir}/best_fold{fold}.pth')\n                not_improved_epochs = 0\n                mlflow.log_metric(\"val_best_cv_score\", score)\n                df_best.to_csv(f\"{output_dir}/df_val_fold{fold}.csv\", index=False)\n            else:\n                not_improved_epochs += 1\n                print('{:.4f} is not improved from {:.4f} epoch {} / {}'.format(score, best_score, not_improved_epochs, config.early_stop_round))\n                if not_improved_epochs >= config.early_stop_round:\n                    print(\"finish training.\")\n                    break\n            mlflow.log_param(\"fold\", fold)\n            mlflow.log_metric(\"val_loss\", valid_loss.avg)\n            mlflow.log_metric(\"val_cv_score\", score)\n            mlflow.log_metric(\"val_best_threshold\", best_threshold)\n\n        for key, value in config.__dict__.items():\n            mlflow.log_param(key, value)\n        mlflow.end_run()\n\n        \n\n\n#     #for bert_lr in [3e-5, 5e-6, 5e-5]:\n#     for bert_lr in [5e-6, 5e-5]:\n#         # base_lr　5e-4で固定\n#         config.base_lr = 5e-4\n        \n#         config = Config()\n#         config.bert_lr = bert_lr\n#         main(config)\n\n#     for dropout in [0, 0.1, 0.2]:\n#         config = Config()\n#         config.dropout = dropout\n#         main(config)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n### adacosなどの実験用に消す\n    # for base_lr in [3e-4, 5e-5, 5e-4]:\n    for s in [50]:\n        # base_lr　5e-4で固定\n        config = Config()\n        config.base_lr = 5e-4\n        config.bert_lr = 5e-6\n\n        print(\"s = \",s)\n        \n        config.s = s\n        main(config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    config.s","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if __name__ == \"__main__\":\n\n#     \"\"\"\n#     # benchmarking\n#     config = Config()\n#     main(config)\n#     config = Config()\n#     config.scheduler_params = {\"patience\": 0, \"factor\": 0.1, \"mode\": \"max\"}\n#     main(config)\n#     \"\"\"\n#     config = Config()\n#     main(config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if __name__ == \"__main__\":\n\n#     # benchmarking\n#     config = Config()\n#     main(config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_loader = torch.utils.data.DataLoader(\n#         train_dataset,\n#         batch_size=config.batch_size,\n#         shuffle=True,\n#         pin_memory=True,\n#         drop_last=True,\n#         num_workers=config.num_workers\n# )\n# device = torch.device(\"cuda\")\n# model = ShopeeNet(config=config)\n\n# model.to(\"cuda\")\n# optimizer = config.optimizer(params=[{\"params\": model.bert.parameters(), \"lr\": config.bert_lr},\n#                                     {\"params\": model.bert_bn.parameters(), \"lr\": config.bert_lr},\n#                                     {\"params\": model.cnn.parameters(), \"lr\": config.base_lr},\n#                                     {\"params\": model.cnn_bn.parameters(), \"lr\": config.base_lr},\n#                                     {\"params\": model.fc.parameters(), \"lr\": config.base_lr},\n#                                     {\"params\": model.final.parameters(), \"lr\": config.base_lr}])\n# scheduler = config.scheduler(optimizer, **config.scheduler_params)\n# criterion = config.loss(**config.loss_params)\n\n# train_loss = train_fn(train_loader, model, criterion, optimizer, device, scheduler=scheduler, epoch=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv(\"../input/train-fold/train_fold.csv\")\n# df[\"filepath\"] = df['image'].apply(lambda x: os.path.join('input/shopee-product-matching/', 'train_images', x))\n# label_encoder = LabelEncoder()\n# df[\"label_group\"] = label_encoder.fit_transform(df[\"label_group\"].values)\n\n# df_train = df[df[\"fold\"] != 0]\n\n# tokenizer = AutoTokenizer.from_pretrained(config.nlp_model_name)\n\n# df_train = df[df[\"fold\"] != 0]\n# df_val = df[df[\"fold\"] == 0]\n\n# train_dataset = ShopeeDataset(df=df_train,\n#                             transforms=config.train_transforms,\n#                             tokenizer=tokenizer)\n# val_dataset = ShopeeDataset(df=df_val,\n#                             transforms=config.val_transforms,\n#                             tokenizer=tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
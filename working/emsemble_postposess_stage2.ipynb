{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# parameters","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/d/kurupical/shopee-exp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport shutil\nimport glob\nimport tqdm\nimport torch\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom cuml.neighbors import NearestNeighbors\nimport cudf, cuml, cupy\nimport gc\nfrom sklearn.preprocessing import normalize\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport re\nfrom pathlib import Path\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PARAMETERS = {\n    \"all_kiccho_cossim\": 0.35+0.2,\n    \"img_kiccho_cossim\": 0.35+0.2,\n    \"text_kiccho_cossim\": 0.55+0.2,\n\n    \"all_kurupical_cossim\": 0.55+0.2,\n    \"img_kurupical_cossim\": 0.6+0.2,\n    \"text_kurupical_cossim\": 0.65+0.2,\n\n    \"all_kiccho_euclidean\": 0.85*0.7,\n    \"img_kiccho_euclidean\": 1.05*0.7,\n    \"text_kiccho_euclidean\": 1.1*0.7,\n\n    \"all_kurupical_euclidean\": 1.1*0.7,\n    \"img_kurupical_euclidean\": 0.8*0.7,\n    \"text_kurupical_euclidean\": 0.75*0.7,\n    \n    \"kiccho_avg_all_cossim\": 0.35+0.2,\n    \"kiccho_max_all_cossim\": 0.4+0.2,\n    \"kiccho_min_all_cossim\": 0.3+0.2,\n    \n    \"kiccho_avg_img_cossim\": 0.35+0.2,\n    \"kiccho_max_img_cossim\": 0.4+0.2,\n    \"kiccho_min_img_cossim\": 0.3+0.2,\n    \n    \"kiccho_avg_text_cossim\": 0.55+0.2,\n    \"kiccho_max_text_cossim\": 0.55+0.2,\n    \"kiccho_min_text_cossim\": 0.45+0.2,\n\n    \"kurupical_avg_all_cossim\": 0.55+0.2,\n    \"kurupical_max_all_cossim\": 0.6+0.2,\n    \"kurupical_min_all_cossim\": 0.4+0.2,\n    \n    \"kurupical_avg_img_cossim\": 0.6+0.2,\n    \"kurupical_max_img_cossim\": 0.65+0.2,\n    \"kurupical_min_img_cossim\": 0.55+0.2,\n    \n    \"kurupical_avg_text_cossim\": 0.65+0.2,\n    \"kurupical_max_text_cossim\": 0.7+0.2,\n    \"kurupical_min_text_cossim\": 0.6+0.2,\n    \n    \"vote\": 16\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kurupical_models = [\n    'all_swin_large_roberta_exp133.pth',\n    'swin_large_exp103.pth'\n]\nkurupical_model_dir = Path(\"/kaggle/input/d/kurupical/shopee-exp\")\n\nkiccho_models = [\n    \"exp470\",\n    \"exp471\"\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /kaggle/input/timm-048/timm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"debug = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/shopee-exp\")\nsys.path.append(\"/kaggle/input/shopee-exp/exp\")\nsys.path.append(\"/kaggle/input/d/kurupical/shopee-exp/exp\")\nsys.path.append(\"/kaggle/input/kaggle-shopee/src\")\nfrom kaggle_shopee.bin.inference_ensemble_kiccho import get_kiccho_embeddings\nfrom kaggle_shopee.utils.time_util import TimeUtil","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from get_model import get_kurupical_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from exp080 import get_cv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug:\n    image_dir = '../input/shopee-product-matching/train_images'\n    df = pd.read_csv(\"/kaggle/input/d/kurupical/shopee-exp/train_fold.csv\")\n    df[\"filepath\"] = df['image'].apply(lambda x: os.path.join(image_dir, x))\n    df = pd.concat([df, df]).reset_index(drop=True)\n#     df = df[df[\"fold\"] == 0]\n    # threshold = 0.5\nelse:\n    image_dir = '../input/shopee-product-matching/test_images'\n    df = pd.read_csv(\"../input/shopee-product-matching/test.csv\")\n    df[\"filepath\"] = df['image'].apply(lambda x: os.path.join(image_dir, x))\n    # threshold = 0.7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# あとで消す\nif not debug:\n    df[\"label_group\"] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_neighbors_euclidean(df, embeddings, threshold, pred_name=\"pred\", min_n=2):\n    print(f\"[EUCLIDEAN]{pred_name}: threshold={threshold}\")\n    if len(df) <= 3:\n        model = NearestNeighbors(n_neighbors=2)\n    else:\n        model = NearestNeighbors(n_neighbors=75)\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    \n    posting_id = df[\"posting_id\"].values\n    preds = []\n    for k in range(len(df)):\n        IDX = np.where(distances[k, ] < threshold)[0]\n        if len(IDX) < min_n:                \n            IDX = np.argsort(distances[k, ])[:min_n]\n        \n        ids = indices[k, IDX]\n        pred = posting_id[ids]\n        preds.append(pred)\n    \n    df[pred_name] = preds\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_neighbors_cossim(df, embeddings, threshold, pred_name=\"pred\", min_n=2):\n    print(f\"[COSSIM] {pred_name}: threshold={threshold}\")\n    preds = []\n    posting_id = df[\"posting_id\"].values\n    \n    CHUNK = 1024 * 2\n    CTS = len(df) // CHUNK\n    if (len(df)%CHUNK) != 0:\n        CTS += 1\n    \n    preds = []\n    with torch.no_grad():\n        embeddings = normalize(embeddings)\n        print(\"norm avg:\", np.linalg.norm(embeddings, axis=1).mean())\n        embeddings = torch.tensor(embeddings).cuda()\n\n        for j in tqdm.tqdm(range( CTS )):\n            a = j * CHUNK\n            b = (j+1) * CHUNK\n            b = min(b, len(df))\n\n            # COSINE SIMILARITY DISTANCE\n            cts = torch.matmul(embeddings, embeddings[a:b].T).T\n            for k in range(b-a):\n                IDX = torch.where(cts[k,]>threshold)[0]\n                if len(IDX) < min_n:                \n                    IDX = torch.argsort(cts[k, ])[-min_n:]   \n                IDX = IDX.detach().cpu().numpy()\n                preds.append(posting_id[IDX])\n            del cts\n            gc.collect()\n            torch.cuda.empty_cache()\n    df[pred_name] = preds\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_neighbors_cossim_agg(df, embeddings1, embeddings2, threshold_avg, threshold_max, threshold_min, pred_name=\"pred\", min_n=2):\n    print(f\"[COSSIM] {pred_name}: threshold_avg={threshold_avg} threshold_max={threshold_max} threshold_min={threshold_min}\")\n    posting_id = df[\"posting_id\"].values\n    \n    CHUNK = 1024 * 2\n    CTS = len(df) // CHUNK\n    if (len(df)%CHUNK) != 0:\n        CTS += 1\n    \n    preds_avg = []\n    preds_max = []\n    preds_min = []\n    with torch.no_grad():\n        embeddings1 = normalize(embeddings1)\n        embeddings2 = normalize(embeddings2)\n        \n        embeddings1 = torch.tensor(embeddings1).cuda()\n        embeddings2 = torch.tensor(embeddings2).cuda()\n        \n        for j in tqdm.tqdm(range( CTS )):\n            a = j * CHUNK\n            b = (j+1) * CHUNK\n            b = min(b, len(df))\n            \n            cts1 = torch.matmul(embeddings1, embeddings1[a:b].T).T\n            cts2 = torch.matmul(embeddings2, embeddings2[a:b].T).T\n            \n            cts_avg = torch.mean(torch.stack([cts1, cts2]), dim=0)\n            cts_max = torch.max(torch.stack([cts1, cts2]), dim=0)[0]\n            cts_min = torch.min(torch.stack([cts1, cts2]), dim=0)[0]\n            \n            for k in range(b-a):\n                IDX_avg = torch.where(cts_avg[k, ]>threshold_avg)[0]\n                if len(IDX_avg) < min_n:                \n                    IDX_avg = torch.argsort(cts_avg[k, ])[-min_n:]\n                IDX_avg = IDX_avg.detach().cpu().numpy()\n                preds_avg.append(posting_id[IDX_avg])\n                \n                IDX_max = torch.where(cts_max[k, ]>threshold_max)[0]\n                if len(IDX_max) < min_n:                \n                    IDX_max = torch.argsort(cts_max[k, ])[-min_n:]\n                IDX_max = IDX_max.detach().cpu().numpy()\n                preds_max.append(posting_id[IDX_max])\n                \n                IDX_min = torch.where(cts_min[k, ]>threshold_min)[0]\n                if len(IDX_min) < min_n:                \n                    IDX_min = torch.argsort(cts_min[k, ])[-min_n:]\n                IDX_min = IDX_min.detach().cpu().numpy()\n                preds_min.append(posting_id[IDX_min])\n                \n            del cts1\n            del cts2\n            del cts_avg\n            del cts_min\n            del cts_max \n            gc.collect()\n            torch.cuda.empty_cache()\n\n    df[f\"{pred_name}_avg\"] = preds_avg\n    df[f\"{pred_name}_max\"] = preds_max\n    df[f\"{pred_name}_min\"] = preds_min\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dicts = []\nembeddings = {}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model_name in kurupical_models:\n    with TimeUtil.timer(model_name):\n        print(\"=================================================\")\n        \n        model_path = str(kurupical_model_dir / model_name)\n        model_dict = {\n            \"model_name\": model_name,\n            \"th_cossim_all\": PARAMETERS[\"all_kurupical_cossim\"],\n            \"th_cossim_img\": PARAMETERS[\"img_kurupical_cossim\"],\n            \"th_cossim_text\": PARAMETERS[\"text_kurupical_cossim\"],\n            \"th_euclidean_all\": PARAMETERS[\"all_kurupical_euclidean\"],\n            \"th_euclidean_img\": PARAMETERS[\"img_kurupical_euclidean\"],\n            \"th_euclidean_text\": PARAMETERS[\"text_kurupical_euclidean\"],\n        }\n        \n        embeddings[f\"{model_name}_img\"], embeddings[f\"{model_name}_text\"], embeddings[f\"{model_name}_all\"] = get_kurupical_embeddings(\n            model_path=model_path, df=df\n        )\n        torch.cuda.empty_cache()\n        \n        for task in [\"all\", \"img\", \"text\"]:\n            embeddings[f\"{model_name}_{task}\"] = normalize(embeddings[f\"{model_name}_{task}\"])\n\n            df = get_neighbors_cossim(df, \n                                      embeddings=embeddings[f\"{model_name}_{task}\"],\n                                      threshold=model_dict[f\"th_cossim_{task}\"],\n                                      pred_name=f\"{model_dict['model_name']}_cossim_{task}\")\n            df = get_neighbors_euclidean(df, \n                                         embeddings=embeddings[f\"{model_name}_{task}\"],\n                                         threshold=model_dict[f\"th_euclidean_{task}\"],\n                                         pred_name=f\"{model_dict['model_name']}_euclidean_{task}\")\n            \n        model_dicts.append(model_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for task in [\"all\", \"img\", \"text\"]:\n    with TimeUtil.timer(f\"kurupical {task}\"):\n        df = get_neighbors_cossim_agg(\n            df=df, \n            embeddings1=embeddings[f\"{kurupical_models[0]}_{task}\"], \n            embeddings2=embeddings[f\"{kurupical_models[1]}_{task}\"],\n            threshold_avg=PARAMETERS[f\"kurupical_avg_{task}_cossim\"], \n            threshold_max=PARAMETERS[f\"kurupical_max_{task}_cossim\"], \n            threshold_min=PARAMETERS[f\"kurupical_min_{task}_cossim\"], \n            pred_name=f\"kurupical_{task}\", \n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del embeddings\ngc.collect()\nembeddings = {}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for exp in kiccho_models:\n    with TimeUtil.timer(f\"{exp}\"):\n        model_name = exp\n        model_dict = {\n            \"model_name\": model_name,\n            \"th_cossim_all\": PARAMETERS[\"all_kiccho_cossim\"],\n            \"th_cossim_img\": PARAMETERS[\"img_kiccho_cossim\"],\n            \"th_cossim_text\": PARAMETERS[\"text_kiccho_cossim\"],\n            \"th_euclidean_all\": PARAMETERS[\"all_kiccho_euclidean\"],\n            \"th_euclidean_img\": PARAMETERS[\"img_kiccho_euclidean\"],\n            \"th_euclidean_text\": PARAMETERS[\"text_kiccho_euclidean\"],\n        }\n         \n        embeddings[f\"{model_name}_all\"], embeddings[f\"{model_name}_img\"], embeddings[f\"{model_name}_text\"] = get_kiccho_embeddings(\n            exp, df, num_workers=4, image_dir=image_dir\n        )\n        \n        for task in [\"all\", \"img\", \"text\"]:\n            embeddings[f\"{model_name}_{task}\"] = normalize(embeddings[f\"{model_name}_{task}\"])\n\n            df = get_neighbors_cossim(df, \n                                      embeddings=embeddings[f\"{model_name}_{task}\"],\n                                      threshold=model_dict[f\"th_cossim_{task}\"],\n                                      pred_name=f\"{model_dict['model_name']}_cossim_{task}\")\n            df = get_neighbors_euclidean(df, \n                                         embeddings=embeddings[f\"{model_name}_{task}\"],\n                                         threshold=model_dict[f\"th_euclidean_{task}\"],\n                                         pred_name=f\"{model_dict['model_name']}_euclidean_{task}\")\n\n        model_dicts.append(model_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for task in [\"all\", \"img\", \"text\"]:\n    with TimeUtil.timer(f\"kiccho {task}\"):\n        df = get_neighbors_cossim_agg(\n            df=df, \n            embeddings1=embeddings[f\"{kiccho_models[0]}_{task}\"], \n            embeddings2=embeddings[f\"{kiccho_models[1]}_{task}\"],\n            threshold_avg=PARAMETERS[f\"kiccho_avg_{task}_cossim\"], \n            threshold_max=PARAMETERS[f\"kiccho_max_{task}_cossim\"], \n            threshold_min=PARAMETERS[f\"kiccho_min_{task}_cossim\"], \n            pred_name=f\"kiccho_{task}\", \n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del embeddings\ngc.collect()\nembeddings = {}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_names = []\nmodel_names.extend([f\"{x['model_name']}_cossim_img\" for x in model_dicts])\nmodel_names.extend([f\"{x['model_name']}_cossim_text\" for x in model_dicts])\nmodel_names.extend([f\"{x['model_name']}_cossim_all\" for x in model_dicts])\nmodel_names.extend([f\"{x['model_name']}_euclidean_img\" for x in model_dicts])\nmodel_names.extend([f\"{x['model_name']}_euclidean_text\" for x in model_dicts])\nmodel_names.extend([f\"{x['model_name']}_euclidean_all\" for x in model_dicts])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for prefix in [\"kurupical\", \"kiccho\"]:\n    for task in [\"img\", \"text\", \"all\"]:        \n        for method in [\"avg\", \"max\", \"min\"]:        \n            model_names.append(f\"{prefix}_{task}_{method}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_predictions(row):\n    x = np.unique(np.concatenate([row['matches'], row[\"title_aggregate\"]]))\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"title_lower\"] = [x.lower() for x in df[\"title\"].values]\ntmp = df.groupby('title_lower').posting_id.agg('unique').to_dict()\ndf['title_aggregate'] = df.title_lower.map(tmp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_predictions_major(row):\n    # x = np.concatenate([row['xlm_roberta_base'], row['distilbert_base'], row[\"bert_base\"], row[\"bert_indonesian\"]])\n    x = np.concatenate(row[model_names].values.reshape(-1))\n    x, counts = np.unique(x, return_counts=True)\n    \n    ret_idx = counts >= PARAMETERS[\"vote\"]\n    return x[ret_idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['matches'] = df.apply(combine_predictions_major, axis=1)\ndf['matches'] = df.apply(combine_predictions, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_unit_from_title(title, unit_name):\n    \"\"\" タイトル title から, 単位名 unit_name の数値特徴を抜き出す\"\"\"\n    \n    title = title.lower().replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n    pattern = f\".*? (\\d+.{unit_name})\"\n    \n    # ary = re.findall(pattern, title, re.S)\n    ary = re.findall('[0-9.-]+' + '\\s*'+ unit_name, title)\n    if len(ary) != 1:\n        return None\n    else:\n        return ary[0].replace(\" \", \"\").replace(unit_name, \"\")\n\ndef vote_for_unit(x, unit_dict):\n    \"\"\"\n    drop_different_unit専用のvote\n    * unit_nameが入っていないデータは無条件に同じグループとする\n    * voteの結果が1件となった場合は, 後処理をしない\n    \n    \"\"\"\n    def isnan(x):\n        if type(x) == float:\n            return True\n        if type(x) == np.ndarray:\n            return False\n    \n    if type(x[1]) == np.ndarray:\n        x_out = np.concatenate(x)\n        x_out, counts = np.unique(x_out, return_counts=True)\n        x_unit_none = [xx for xx in x_out if isnan(unit_dict[xx])]\n        \n        ret_idx = counts == 2\n        if ret_idx.sum() == 1:\n            return x[0]\n        x_out = x_out[ret_idx].tolist()\n        return x_out + x_unit_none\n    else:\n        return x[0]    \n\ndef drop_different_unit(df, pred_name, unit_name, pred_name_out=None):\n    \"\"\"\n    同じグループのもののうち, 単位 unit_name の数字が違うデータは別グループとする\n    例: unit_name = \"ml\" -> 50ml と 100ML は別グループ\n    \n    params\n    @df: \n    @pred_name: 検査する予測結果の列名\n    @unit_name: 単位名(例: ml, gram, ...)\n    @pred_name_out: 後処理後の列名(Noneならpred_nameと同じ)\n    \"\"\"\n    if pred_name_out is None:\n        pred_name_out = pred_name\n    \n    unit_pred_name = f\"pred_unit_{unit_name}\"\n    \n    df[f\"unit_{unit_name}\"] = [get_unit_from_title(title, unit_name) for title in df[\"title\"].values]\n    tmp = df.groupby(f\"unit_{unit_name}\")[\"posting_id\"].agg('unique').to_dict()\n    df[unit_pred_name] = df[f\"unit_{unit_name}\"].map(tmp)\n    print(f\"{df[unit_pred_name].notnull().sum()} titles have unit_name '{unit_name}'. n_unique: {len(tmp)}\")\n    \n    unit_dict = df[[\"posting_id\", unit_pred_name]].set_index(\"posting_id\")[unit_pred_name].to_dict()\n    \n    df[pred_name_out] = [vote_for_unit(x, unit_dict) for x in df[[pred_name, unit_pred_name]].values]\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug:\n    df[\"pred\"] = df[\"matches\"]\n    df[\"pred\"] = [np.unique(x) for x in df[\"pred\"].values]\n    print(get_cv(df))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for unit_name in [\"gr\", \"ml\"]:\n    df = drop_different_unit(df, \n                             pred_name=\"matches\", \n                             unit_name=unit_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if debug:\n    df[\"pred\"] = df[\"matches\"]\n    df[\"pred\"] = [np.unique(x) for x in df[\"pred\"].values]\n    print(get_cv(df))\nelse:\n    df[\"matches\"] = [' '.join(np.unique(x)) for x in df[\"matches\"].values]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[[\"posting_id\", \"matches\"]].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}